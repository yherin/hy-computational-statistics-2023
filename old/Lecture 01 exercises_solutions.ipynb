{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Mathematics and Statistics  \n",
    "MAST32001 Computational Statistics, Autumn 2022  \n",
    "Luigi Acerbi  \n",
    "Based on notebook by Antti Honkela\n",
    "\n",
    "# Lecture 1: Floating point numbers and numerics of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating point number basics\n",
    "\n",
    "Real numbers are typically represented as floating point numbers in computers. Floating point numbers use a fixed storage size and hence can offer only finite precision. Floating point numbers do not fulfill the usual axioms of real numbers, which means they can sometimes behave in unexpected ways.\n",
    "\n",
    "Background reading on floating point numbers:\n",
    "\n",
    "http://floating-point-gui.de/formats/fp/  \n",
    "http://floating-point-gui.de/errors/rounding/  \n",
    "http://floating-point-gui.de/errors/comparison/  \n",
    "http://floating-point-gui.de/errors/propagation/  \n",
    "https://hal.archives-ouvertes.fr/hal-00128124v5/document  \n",
    "and references therein.\n",
    "\n",
    "## Useful links\n",
    "\n",
    "https://courses.helsinki.fi/fi/aycsm90004en/135221588 : \"Data Analysis with Python\" MOOC  \n",
    "http://www.learnpython.org/ : Nice interactive Python tutorial  \n",
    "https://docs.python.org/3/tutorial/index.html : Official documentation for Python3  \n",
    "https://docs.scipy.org/doc/numpy/user/quickstart.html : Tutorial for one of the most important Python modules, SciPy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Computing with floating point numbers\n",
    "\n",
    "Write a program to increment `x = 0.0` by `0.1` 100 times. Compute `x - 10`. How do you interpret the result?\n",
    "\n",
    "Check other examples with different increments. In which cases can you get an exact result? Can you come up with a class of instances where the result is exact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9539925233402755e-14\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x = 0.0\n",
    "for i in range(100):\n",
    "    x += 0.1\n",
    "print(x - 10)\n",
    "\n",
    "# Try this instead\n",
    "x = 0.0\n",
    "for i in range(100):\n",
    "    x += 0.25\n",
    "print(x - 25)\n",
    "# Why does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing log-probabilities\n",
    "\n",
    "Probabilities can sometimes be difficult to compute with floating point numbers as they can be very small non-negative numbers. These problems can often be avoided by using logarithms and storing $ \\log(p) $ instead of $ p $.\n",
    "\n",
    "Compute numerically the following probabilities and report them in the format $x \\cdot 10^y$:\n",
    "1. The probability of randomly drawing the 8191-letter HIV-1 genome from the 4-letter DNA alphabet.\n",
    "2. The probability that you need exactly 5000 throws of a regular 6-sided die to get the first 6. (*Hint*: [Geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution).)\n",
    "3. The probability that $ x = 200 $ when $ x \\sim \\mathrm{Poisson}(1)$.\n",
    "\n",
    "*Hints*: \n",
    "- The Python package 'numpy' contains basic numerical functions you will need. Just use `np.log()` for `log()` etc. You can use the properties of logarithms to convert natural logarithms to base 10 to make them more human-readable.\n",
    "- As commonly done, in point 3 above we denoted with $x \\sim P(\\theta)$ that $x$ is an instance of a random variable drawn from the probability density (or probability mass function) $P$ with parameters $\\theta$. In example 3, $P$ is a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) with rate parameter $\\lambda = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 2.000 * 10^-5\n",
      "p = 3.362 * 10^-4932\n",
      "p = 2.482 * 10^-397\n",
      "p = 4.665 * 10^-376\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to print the values in the requested format.\n",
    "# For all y, we have\n",
    "#   p = 10^log10p = 10^y * 10^(log10p - y)\n",
    "# where the logarithm is in base 10.\n",
    "# By choosing y to be largest integer not greater than log10p, we have 1 <= x < 10.\n",
    "def pretty_print_log10(log10p):\n",
    "    \"\"\"Print a log probability in pretty scientific notation x * 10^y.\"\"\"\n",
    "    y = np.floor(log10p)\n",
    "    x = 10**(log10p-y)\n",
    "    print(\"p = \" + \"{:.3f}\".format(x) + \" * 10^{:.0f}\".format(y))\n",
    "\n",
    "# Test pretty print function\n",
    "pretty_print_log10(np.log10(0.00002))\n",
    "\n",
    "#1\n",
    "# Probability of drawing one letter from 4-letter alphabet is 1/4\n",
    "# Assuming probabilities are independent we get Pr(genome) = 0.25^8191\n",
    "logp_hiv = 8191*np.log10(0.25)\n",
    "pretty_print_log10(logp_hiv)\n",
    "\n",
    "#2\n",
    "# Probability for 4999 throws before first 6 is given by geometric distribution with p = 1/6\n",
    "logp_dice = 4999*np.log10(5/6)+np.log10(1/6)\n",
    "pretty_print_log10(logp_dice)\n",
    "\n",
    "#3\n",
    "# Probability for x=200 when x ~ Poisson(1) is given by exp(-1)/200!.\n",
    "# Logarithm of n! can be computed as the sum_i=1^n (log(i))\n",
    "logp_poi = -np.log10(np.exp(1)) - sum([np.log10(i+1) for i in range(200)])\n",
    "pretty_print_log10(logp_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Log-sum-exp trick when working with log-probabilities\n",
    "\n",
    "Assuming one is working with log-probabilities as suggested above, one often runs into the need to normalise a set of log-probabilities $\\textbf{x} = (x_1, \\ldots, x_N)$. To do this, it is necessary to compute\n",
    "$$ z = \\log\\left( \\sum_{i=1}^N \\exp(x_i) \\right). $$\n",
    "This can be difficult as $ \\exp() $ can very easily overflow or underflow. These problems can be avoided by using the log-sum-exp (or logsumexp) trick discussed e.g. at\n",
    "https://lips.cs.princeton.edu/computing-log-sum-exp/\n",
    "\n",
    "1. Try to compute $ z $ directly for $\\textbf{x} = [-1000, -999, -1000]$.\n",
    "2. Compute $z$ again using the log-sum-exp trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-998.448555286068\n",
      "p = 2.395 * 10^-434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luigi\\AppData\\Local\\Temp/ipykernel_3192/3222279817.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  z1 = np.log(np.sum(np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "x = [-1000, -999, -1000]\n",
    "z1 = np.log(np.sum(np.exp(x)))\n",
    "print(z1)\n",
    "\n",
    "#2\n",
    "# log-sum-exp trick: subtract max(x) before taking exp() and add it back afterwards\n",
    "def logsumexp(x):\n",
    "    \"\"\"Return log of sum of exponential of provided log-probability vector.\"\"\"\n",
    "    M = np.max(x)\n",
    "    return np.log(np.sum(np.exp(x-M)))+M\n",
    "\n",
    "z2 = logsumexp(x)\n",
    "print(z2)\n",
    "pretty_print_log10(z2/np.log(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Useful special functions\n",
    "\n",
    "Probability distributions often involve special functions such as the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) $\\Gamma(z)$. The gamma function is also useful as $ n! = \\Gamma(n+1) $, where $n!$ is $n$ factorial. Note that almost all numerical packages will offer a function that directly computes the *logarithm* of the Gamma function (often called something like `gammaln`).\n",
    "\n",
    "1. Check the manual of the Python package `scipy.special` to find the different forms of gamma function it offers.\n",
    "2. Redo task 3 of Exercise 2 using a suitable gamma function call from `scipy.special`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 4.665 * 10^-376\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from scipy.special import gammaln\n",
    "logp_poi = (-1 - gammaln(201))*np.log10(np.exp(1))\n",
    "pretty_print_log10(logp_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Numerical algorithms\n",
    "\n",
    "As an example of a numerical computation, let us consider the estimation of the variance of $ n $ numbers $ x_1, \\dots, x_n $.\n",
    "\n",
    "Denoting the mean of the numbers by $ \\bar{x}, $ the unbiased estimate of the sample variance is\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 =\n",
    "  \\frac{1}{n-1} \\sum_{i=1}^n (x_i^2 - 2 x_i \\bar{x} + \\bar{x}^2) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - 2 n \\bar{x}^2 + n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right).\n",
    "$$\n",
    "\n",
    "The variance can be estimated in a numerically stable manner using the first form, but this requires two passes through the data: first to compute the mean and then the second time to compute the sum of squared differences. The last form can be evaluated in single pass, but computing the difference of two potentially large positive numbers is numerically unstable.\n",
    "\n",
    "1. Write a function for computing the variance of a given array of numbers using the two-pass approach:\n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i $$\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 $$\n",
    "2. Write a function for computing the variance of a given array of numbers using the one-pass approach:\n",
    "$$ s^2 = \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right). $$\n",
    "3. Test your functions by generating 1000 random number from the distribution $ N(10^9, 1) $. (*Hint*: `numpy.random.randn()`)\n",
    "4. Implement Welford's accurate one-pass algorithm and test it with your data. (See e.g. http://jonisalonen.com/2013/deriving-welfords-method-for-computing-variance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0773882831126873\n",
      "1443.2352352352352\n",
      "1.0773882503378813\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "#1\n",
    "# Slow two-pass implementation with loops\n",
    "def two_pass_loop(x):\n",
    "    mean = 0\n",
    "    n = len(x)\n",
    "    for x_i in x:\n",
    "        mean += x\n",
    "    mean /= n\n",
    "    variance = 0\n",
    "    for x_i in x:\n",
    "        variance += (x_i - mean)**2\n",
    "    variance /= n-1\n",
    "    return variance\n",
    "\n",
    "# Faster two-pass implementation using NumPy functions\n",
    "def two_pass(x):\n",
    "    n = len(x)\n",
    "    mean = np.mean(x)\n",
    "    variance = 1/(n-1)*np.sum((x-mean)**2)\n",
    "    return variance\n",
    "\n",
    "#2\n",
    "# Slow one-pass implementation with a loop\n",
    "def one_pass_loop(x):\n",
    "    n = len(x)\n",
    "    square_sum_x = 0\n",
    "    sum_x = 0\n",
    "    for x_i in x:\n",
    "        square_sum_x += x_i**2\n",
    "        sum_x += x_i\n",
    "    return (square_sum_x-sum_x**2/n)/(n-1)\n",
    "\n",
    "#3\n",
    "sample = npr.normal(1e9, 1, size=1000)\n",
    "print(two_pass(sample))  # variance of sample computed using two-pass approach\n",
    "print(one_pass_loop(sample))  # variance of sample computed using one-pass approach\n",
    "\n",
    "#4\n",
    "# NOTE: This pure Python implementation is inefficient - you should always use NumPy functions instead!\n",
    "def welfords(x):\n",
    "    m = 0\n",
    "    s = 0\n",
    "    for k, x_i in enumerate(x):\n",
    "        oldm = m\n",
    "        m += (x_i-m)/(k+1)\n",
    "        s+= (x_i-m)*(x_i-oldm)\n",
    "    return s/k # note that indexing of array in python starts from 0 and ends to length(array)-1\n",
    "                 # so at the end of for loop k=len(x)-1\n",
    "\n",
    "print(welfords(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus extra: Early history of digital computers\n",
    "\n",
    "Statistics and computers have a long common history, and the first electronic computer Colossus was built by the British to perform statistical computations for breaking a German cryptosystem during World War II. This relatively unknown part of history is reported in detail in\n",
    "http://www.rutherfordjournal.org/article030109.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "48562baf5ec4044852c40c81624b046fbb3741edb6df52b5d8ff6faefb753e30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
