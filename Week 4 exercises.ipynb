{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Mathematics and Statistics  \n",
    "MAST32001 Computational Statistics, Autumn 2022  \n",
    "Luigi Acerbi\n",
    "\n",
    "# Week 4 exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MCMC convergence diagnostics (4 pts)\n",
    "\n",
    "The file loaded below contains samples from 3 chains of Metropolis-Hastings sampling for the bimodal target \n",
    "$$\\pi^*(\\theta) = \\exp(-\\gamma (\\theta^2-1)^2)$$\n",
    "with $\\gamma = 4$. Warm-up samples have already been removed from the saved results, so you do not need to remove warm-up samples.\n",
    "\n",
    "1. Evaluate the $\\hat{R}$-statistic defined in Sec. 8.1.1 of the course notes using the original 3 chains. Report your result in Moodle.\n",
    "2. Evaluate the split-$\\hat{R}$ (see Sec. 8.1.1) by splitting the chains in half to obtain 6 chains. Report your result in Moodle.\n",
    "3. Compute the effective sample size (ESS) for the first chain (1000 samples), when we know the estimates $\\mu = 0$, $\\sigma^2 = 0.9185$ from an independent long simulation. Use the truncated sum estimate from Sec. 8.1.2 of the course notes. Report your result in Moodle.\n",
    "   *Hint*:  Use Eqs. 8.1 and 8.4, for which you will have to find the upper bound $K$ of the sum as indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "1.02592438270425\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.distributions import rv_frozen\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "samples = pd.read_csv('https://raw.githubusercontent.com/lacerbi/compstats-files/main/data/bimod_samples.txt', header=None, sep='\\t').values\n",
    "\n",
    "# 1.1\n",
    "\n",
    "def compute_B(samples: np.ndarray) -> float:\n",
    "    n, m = samples.shape\n",
    "    scalar = n / (m - 1)\n",
    "    return scalar * np.sum([(np.mean(samples[:, j], axis=0) - np.mean(samples))**2 for j in range(m) ])\n",
    "\n",
    "\n",
    "def compute_W(samples: np.ndarray) -> float:\n",
    "    def compute_S(j: int) -> float:\n",
    "        return np.mean((samples[:, j] - samples[:, j].mean())**2)\n",
    "    _, m = samples.shape\n",
    "    return np.mean([compute_S(j) for j in range(m)])\n",
    "\n",
    "def rhat(samples: np.ndarray) -> float:\n",
    "    n, _ = samples.shape\n",
    "    w = compute_W(samples)\n",
    "    b = compute_B(samples)\n",
    "\n",
    "    var = ((n-1)/n) * w + (1/n) * b\n",
    "    return np.sqrt(var / w)\n",
    "\n",
    "print(samples.shape)\n",
    "print(rhat(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_samples = np.zeros((500, 6))\n",
    "split_samples[:, 0] = samples[:500, 0]\n",
    "split_samples[:, 1] = samples[500:, 0]\n",
    "split_samples[:, 2] = samples[:500, 1]\n",
    "split_samples[:, 3] = samples[500:, 1]\n",
    "split_samples[:, 4] = samples[:500, 2]\n",
    "split_samples[:, 5] = samples[500:, 2]\n",
    "\n",
    "\n",
    "assert not np.equal(0, split_samples).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rhat(samples: np.ndarray) -> float:\n",
    "    n, m = samples.shape\n",
    "    assert n > m, \"Expect shape (samples, chains)\"\n",
    "    split_at = n // 2\n",
    "    split_samples = np.zeros((split_at, m*2))\n",
    "    # do the split\n",
    "    for i in range(0, split_samples.shape[1]):\n",
    "        if i % 2 == 0:\n",
    "            split_samples[:, i] = samples[split_at:, i//2]\n",
    "        else:\n",
    "            split_samples[:, i] = samples[:split_at, i//2]\n",
    "    return rhat(split_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n",
      "1.1157934720570248\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "print(split_samples.shape)\n",
    "print(rhat(split_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rhat(chains):\n",
    "    \"\"\"\n",
    "    Calculate the R-hat diagnostic for a set of MCMC chains.\n",
    "\n",
    "    Parameters:\n",
    "    - chains: Array of shape (num_chains, chain_length)\n",
    "\n",
    "    Returns:\n",
    "    - rhat: R-hat diagnostic value\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chains and chain length\n",
    "    num_chains, chain_length = chains.shape\n",
    "\n",
    "    # Calculate the within-chain variance for each chain\n",
    "    within_chain_var = np.var(chains, axis=1, ddof=1)\n",
    "\n",
    "    # Calculate the overall mean across all chains\n",
    "    overall_mean = np.mean(chains)\n",
    "\n",
    "    # Calculate the between-chain variance\n",
    "    between_chain_var = chain_length / (num_chains - 1) * np.sum((np.mean(chains, axis=1) - overall_mean)**2)\n",
    "\n",
    "    # Calculate the pooled within-chain variance\n",
    "    pooled_within_chain_var = np.mean(within_chain_var)\n",
    "\n",
    "    # Calculate the estimated variance of the target distribution\n",
    "    var_hat = (chain_length - 1) / chain_length * pooled_within_chain_var + between_chain_var / chain_length\n",
    "\n",
    "    # Calculate R-hat\n",
    "    rhat = np.sqrt(var_hat / pooled_within_chain_var)\n",
    "\n",
    "    return rhat\n",
    "\n",
    "def calculate_split_rhat(chains):\n",
    "    \"\"\"\n",
    "    Calculate the split R-hat diagnostic for a set of MCMC chains.\n",
    "\n",
    "    Parameters:\n",
    "    - chains: Array of shape (num_chains, chain_length)\n",
    "\n",
    "    Returns:\n",
    "    - split_rhat: Split R-hat diagnostic value\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chains and chain length\n",
    "    num_chains, chain_length = chains.shape\n",
    "\n",
    "    # Split the chains into two halves\n",
    "    half_length = chain_length // 2\n",
    "    chains_1 = chains[:, :half_length]\n",
    "    chains_2 = chains[:, half_length:]\n",
    "\n",
    "    # Calculate the R-hat for each half\n",
    "    rhat_1 = calculate_rhat(chains_1)\n",
    "    rhat_2 = calculate_rhat(chains_2)\n",
    "\n",
    "    # Calculate the split R-hat\n",
    "    split_rhat = np.sqrt((rhat_1**2 + rhat_2**2) / 2)\n",
    "\n",
    "    return split_rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound for k: 85\n",
      "13.763929528261746\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "mu = 0\n",
    "sigma_sq = .9185\n",
    "first_chain = samples[:, 0]\n",
    "assert first_chain.shape == (1000,)\n",
    "\n",
    "def compute_rho(samples: np.ndarray, k: int, mu: float = mu, sigma_sq: float = sigma_sq) -> float:\n",
    "    rho_i = 0\n",
    "    for i in range(samples.shape[0] - k):\n",
    "        rho_i += (samples[i] - mu) * (samples[i+k] - mu)\n",
    "    return rho_i * (1 / (samples.shape[0] * sigma_sq))\n",
    "\n",
    "def find_k_upper_bound(samples: np.ndarray, k: int) -> int:\n",
    "    i = 0\n",
    "    max_iterations = 1000\n",
    "    k = 0\n",
    "    while True:\n",
    "        rho_k_plus_1 = compute_rho(samples, k+1)\n",
    "        rho_k_plus_2 = compute_rho(samples, k+2)\n",
    "        if np.sum(rho_k_plus_1 + rho_k_plus_2) < 0 and k % 2 == 1:\n",
    "            break\n",
    "        k += 1\n",
    "        i += 1\n",
    "        if i > max_iterations:\n",
    "            raise ValueError('Max iterations reached')\n",
    "    return k\n",
    "k = find_k_upper_bound(first_chain, 0)\n",
    "print(f\"Upper bound for k: {k}\")\n",
    "\n",
    "M = first_chain.shape[0]\n",
    "ESS = M / (1 + (2 * np.sum([compute_rho(first_chain, k) for k in range(1, k+1)])))\n",
    "print(ESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCMC sampling for a Bayesian regression model (6 pts)\n",
    "\n",
    "In this task we will apply MCMC sampling to a linear regression model that predicts the birth weight ('bwt', $y_i$) for old mothers (age >= 30) as a function of the age of the mother, duration of the pregnancy and weight of the mother ('age', 'gestation', 'weight'; $\\mathbf{x}_i$).\n",
    "\n",
    "As our model we will consider a linear regression model fitted to the observations $((\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\dots, (\\mathbf{x}_n, y_n))$. The code below will load the matrix `x` (each row is one sample) and vector `y`. The values $\\mathbf{x}_1, \\dots, \\mathbf{x}_n$ are the *input values* and $y_1, \\dots, y_n$ are the *target values*. The loading code normalises all data to have zero mean and unit variance to get the regression coefficients to a shared scale.\n",
    "\n",
    "We model the data with a linear regression model\n",
    "$$ y_i = \\mathbf{x}_i \\boldsymbol{\\beta} + \\epsilon_i, $$\n",
    "where $\\mathbf{x}_i$ is a row vector of input values, $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\beta_3)^T$ is a column vector of regression coefficients and $\\epsilon_i$ is a Gaussian noise term $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_x^2)$.\n",
    "\n",
    "The likelihood of the model is\n",
    "$$ p(Y \\mid X, \\beta, \\sigma_x) = \\prod_{i=1}^n \\mathcal{N}(y_i; \\mathbf{x}_i \\boldsymbol{\\beta}, \\sigma_x^2). $$\n",
    "\n",
    "The regression coefficients $\\beta_j$ have a hierarchical prior\n",
    "$$ p(\\beta_j | \\sigma_{\\beta}) = \\mathcal{N}(\\beta_j;\\; 0, \\sigma_{\\beta}^2), \\quad j = 1, 2, 3, $$\n",
    "with standard deviation $\\sigma_{\\beta}$.\n",
    "Its prior is\n",
    "$$ p(\\sigma_{\\beta}) = \\mathrm{Gamma}(k_{\\beta} = 2, \\theta_{\\beta} = 1/2) $$\n",
    "with shape $k_{\\beta}=2$ and scale $\\theta_{\\beta} = 1/2$.\n",
    "The prior of the noise standard deviation $\\sigma_x$ is\n",
    "$$ p(\\sigma_{x}) = \\mathrm{Gamma}(k_{x} = 2, \\theta_{x} = 1/2) $$\n",
    "with shape $k_{x}=2$ and scale $\\theta_{x} = 1/2$.\n",
    "As usual, we assume the prior factorizes as $p(\\sigma_\\beta, \\sigma_x) = p(\\sigma_\\beta) p(\\sigma_x)$.\n",
    "\n",
    "To ensure the standard deviations are positive, express them as $\\sigma_{\\beta} = \\exp(s_{\\beta})$ and $\\sigma_x = \\exp(s_x)$. Remember to apply the density transformation to transform the priors over $\\sigma_{\\beta}$ and $\\sigma_x$ to those over $s_{\\beta}$ and $s_x$!\n",
    "\n",
    "The full set of model parameters for MCMC is thus $\\theta = (s_{\\beta}, s_x, \\beta_1, \\beta_2, \\beta_3)$.\n",
    "\n",
    "Write a Metropolis-Hastings MCMC sampler to sample from the joint posterior distribution of all model parameters $\\theta$, $$p(\\theta \\mid X, Y) = p(s_{\\beta}, s_x, \\beta_1, \\beta_2, \\beta_3 \\mid X, Y).$$\n",
    "\n",
    "1. Implement a Metropolis-Hastings MCMC sampler with proposal $q(\\theta' ; \\theta) = \\mathcal{N}(\\theta';\\; \\theta, 0.04^2 \\mathbf{I})$, i.e. a multivariate normal proposal centred around the current state with standard deviation 0.04 for each component.\n",
    "2. Run the sampler for 5000 iterations starting from each of the 4 initial points defined by the columns of `inits`. Discard the first 2500 iterations for each run as warm-up. Compute the split-$\\hat{R}$ statistic for the samples of $\\theta$. Report the largest split-$\\hat{R}$ over different components to Moodle.\n",
    "3. Check which variable is having convergence issues. Increase the proposal standard deviation for that component to 0.4 while keeping the proposals for the other components the same. Repeat the sampling as above and report the largest split-$\\hat{R}$ over different components to Moodle.\n",
    "4. Report the posterior mean of the log-standard deviation $s_{\\beta}$ obtained from combining all the 10000 retained samples from the latter sampler to Moodle.\n",
    "\n",
    "*Notes*: \n",
    "- Please note that all computations and results are based on the unbounded variables $s_{\\beta}$ and $s_x$. For the purpose of this exercise, there is no need to transform anything back to the original space of $\\sigma_{\\beta}$ and $\\sigma_x$.\n",
    "- The [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution) has two common representations, one in terms of shape and scale parameters ($k$ and $\\theta$) and one in terms of shape and rate parameters ($\\alpha$ and $\\beta$). Please check that you are using the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy import stats\n",
    "\n",
    "# Load the data set\n",
    "babies_full = pd.read_csv(\"https://raw.githubusercontent.com/lacerbi/compstats-files/main/data/babies2.txt\", sep='\\t')\n",
    "\n",
    "# Pick a subset\n",
    "babies = babies_full.loc[(babies_full['age']>=30).values,:]\n",
    "\n",
    "x = babies[['age', 'gestation', 'weight']].values.astype(float)\n",
    "y = babies[['bwt']].values.astype(float).squeeze()\n",
    "\n",
    "# Remove mean from inputs\n",
    "x -= np.mean(x, 0)\n",
    "# Standardise input variance\n",
    "x /= np.std(x, 0)\n",
    "\n",
    "# Remove mean from outputs\n",
    "y -= np.mean(y, 0)\n",
    "# Standardise output variance\n",
    "y /= np.std(y, 0)\n",
    "\n",
    "inits = np.array([[ 1.67272789, -0.02134183, -0.78116796, -1.77420787],\n",
    "                  [-0.6030697,   0.4464263,   0.3627991,  -0.7342916 ],\n",
    "                  [-1.32685026, -0.37427079, -0.06744599,  0.21175491],\n",
    "                  [ 0.87702047, -0.54171875, -0.44736686, -2.39045985],\n",
    "                  [ 1.00631791, -1.34638203, -0.40343913, -0.64535026]])\n",
    "\n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable\n",
    "\n",
    "rng = npr.default_rng(1234)\n",
    "\n",
    "def log_sigma_beta_prior(s: float) -> float:\n",
    "    return stats.gamma(a=2, scale=1/2).logpdf(s)\n",
    "\n",
    "def log_sigma_x_prior(s: float) -> float:\n",
    "    return stats.gamma(a=2, scale=1/2).logpdf(s)\n",
    "\n",
    "def log_beta_prior(beta: np.ndarray, s: float) -> float:\n",
    "    return stats.norm(0, s**2).logpdf(beta) + s\n",
    "\n",
    "def log_likelihood(y: float, xi: np.ndarray, beta: np.ndarray, s: np.ndarray) -> float:\n",
    "    return np.sum(stats.norm(xi @ beta, s**2).logpdf(y))\n",
    "\n",
    "def log_factorised_prior(beta: np.ndarray, sigma_beta: float, sigma_x: float) -> float:\n",
    "    # sigma and beta are transformed by exp to ensure they are positive\n",
    "    return np.sum(log_sigma_beta_prior(sigma_beta) + log_sigma_x_prior(sigma_x) + log_beta_prior(beta, sigma_beta))\n",
    "\n",
    "def log_posterior(theta: np.ndarray, y: float, xi: np.ndarray) -> float:\n",
    "    sigma_beta = np.exp(theta[0])\n",
    "    sigma_x = np.exp(theta[1])\n",
    "    beta = theta[2:]\n",
    "    prior = log_factorised_prior(beta, sigma_beta, sigma_x) + sigma_beta + sigma_x\n",
    "    lh = log_likelihood(y, xi, beta, sigma_x)\n",
    "    if np.isnan(lh).any():\n",
    "        print(\"NAN likelihood\")\n",
    "    if np.isnan(prior).any():\n",
    "        print(\"NAN prior\")\n",
    "    return prior + lh\n",
    "\n",
    "\n",
    "def metropolis_hastings(theta0: np.ndarray, \n",
    "                        n: int, \n",
    "                        log_target: Callable[..., np.ndarray], \n",
    "                        proposal: Callable[..., np.ndarray],\n",
    "                        ) -> tuple[np.ndarray, float]:\n",
    "    theta = theta0\n",
    "    samples_3_1 = np.zeros(shape=(n, theta0.shape[0]))\n",
    "    accepts = 0\n",
    "    for i in range(n):\n",
    "        theta_prop = proposal(theta)\n",
    "        u = rng.uniform(size=theta0.shape[0])\n",
    "        x = log_target(theta_prop) - log_target(theta)\n",
    "        if (np.log(u) < x).all() :\n",
    "            theta = theta_prop\n",
    "            accepts += 1\n",
    "        samples_3_1[i] = theta\n",
    "    return samples_3_1, accepts / n\n",
    "\n",
    "\n",
    "def proposal(theta: np.ndarray) -> np.ndarray:\n",
    "    s = np.eye(theta.shape[0]) *(.04**2)\n",
    "    return rng.multivariate_normal(theta, s)\n",
    "\n",
    "def modified_proposal(theta: np.ndarray) -> np.ndarray:\n",
    "    s = np.eye(theta.shape[0]) *(.04**2)\n",
    "    s[0, 0] = 0.4**2\n",
    "    return rng.multivariate_normal(theta, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 1 acceptance rate: 0.0732\n",
      "Chain 2 acceptance rate: 0.067\n",
      "Chain 3 acceptance rate: 0.067\n",
      "Chain 4 acceptance rate: 0.082\n"
     ]
    }
   ],
   "source": [
    "n_samples = 5000\n",
    "n_params, n_chains,  = inits.shape\n",
    "chains = np.zeros(( n_samples//2, n_chains, n_params))\n",
    "for chain in range(n_chains):\n",
    "    samples_3_1, acceptance_rate = metropolis_hastings(\n",
    "        theta0=inits[:,chain],\n",
    "        n=5000,\n",
    "        log_target=lambda theta: log_posterior(theta, y, x),\n",
    "        proposal=proposal,\n",
    "    )\n",
    "    chains[:, chain, :] = samples_3_1[n_samples//2:]\n",
    "    print(f'Chain {chain+1} acceptance rate: {acceptance_rate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_beta_chains, sigma_x_chains = chains[:, :, 0], chains[:, :, 1]\n",
    "beta0_chains, beta1_chains, beta2_chains, = chains[:, :, 2], chains[:, :, 3], chains[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.022390944210751 1.0082237435637955 1.014433626511401 1.0038971046733112 1.0179332119709799\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rhat(sigma_beta_chains),\n",
    "    rhat(sigma_x_chains),\n",
    "    rhat(beta0_chains),\n",
    "    rhat(beta1_chains),\n",
    "    rhat(beta2_chains),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1974868991153376 1.0245212297478652 1.0242331521546668 1.0282028844553603 1.022427927273735\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    split_rhat(sigma_beta_chains),\n",
    "    split_rhat(sigma_x_chains),\n",
    "    split_rhat(beta0_chains),\n",
    "    split_rhat(beta1_chains),\n",
    "    split_rhat(beta2_chains),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 1 acceptance rate: 0.0382\n",
      "Chain 2 acceptance rate: 0.0384\n",
      "Chain 3 acceptance rate: 0.0402\n",
      "Chain 4 acceptance rate: 0.0526\n"
     ]
    }
   ],
   "source": [
    "n_samples = 5000\n",
    "n_params, n_chains,  = inits.shape\n",
    "chains_2 = np.zeros(( n_samples//2, n_chains, n_params))\n",
    "for chain in range(n_chains):\n",
    "    samples_3_2, acceptance_rate = metropolis_hastings(\n",
    "        theta0=inits[:,chain],\n",
    "        n=5000,\n",
    "        log_target=lambda theta: log_posterior(theta, y, x),\n",
    "        proposal=modified_proposal,\n",
    "    )\n",
    "    chains_2[:, chain, :] = samples_3_2[n_samples//2:]\n",
    "    print(f'Chain {chain+1} acceptance rate: {acceptance_rate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_beta_chains, sigma_x_chains = chains_2[:, :, 0], chains_2[:, :, 1]\n",
    "beta0_chains, beta1_chains, beta2_chains, = chains_2[:, :, 2], chains_2[:, :, 3], chains_2[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0295321591242144"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\n",
    "    split_rhat(sigma_beta_chains),\n",
    "    split_rhat(sigma_x_chains),\n",
    "    split_rhat(beta0_chains),\n",
    "    split_rhat(beta1_chains),\n",
    "    split_rhat(beta2_chains),\n",
    "]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjack/.cache/pypoetry/virtualenvs/computational-statistics-qlF0ErcH-py3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/sjack/.cache/pypoetry/virtualenvs/computational-statistics-qlF0ErcH-py3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5086428137835249\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_beta_posterior = sigma_beta_chains.flatten()\n",
    "assert sigma_beta_posterior.shape == (10000, )\n",
    "sns.displot(np.exp(sigma_beta_posterior), kde=True)\n",
    "print(sigma_beta_posterior.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importance sampling (4 pts)\n",
    "\n",
    "Develop an importance sampler for the bimodal target\n",
    "$$\\pi(\\theta) = \\sum_{i=1}^2 p_i \\mathcal{N}(\\theta ; \\mu_i, \\sigma_i^2),$$\n",
    "where $p_1 = p_2 = 1/2$ and $\\mu_1 = -1, \\mu_2 = 1$.\n",
    "Use $\\mathrm{Laplace}(0, b)$ with a suitable $b$ as the proposal and evaluate the expectation $\\mathbb{E}[(\\theta-1)^2]$ when\n",
    "1. $\\sigma_1^2 = \\sigma_2^2 = 0.5$.\n",
    "2. $\\sigma_1^2 = \\sigma_2^2 = 0.1$.\n",
    "\n",
    "The required tolerance for the answer is $\\pm 0.1$.\n",
    "\n",
    "In order to estimate the accuracy of your answer, it is recommended to run the sampler a few times and compute the standard deviation of the values you obtain. Monte Carlo error scales as $1/\\sqrt{n}$ with the number of iterations $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "LAPLACE_LOC = 0\n",
    "\n",
    "\n",
    "def sample_laplace_proposal(b: float) -> np.ndarray:\n",
    "    return stats.laplace.rvs(loc=LAPLACE_LOC, scale=b)\n",
    "\n",
    "def pdf_laplace_proposal(x: float, b: float) -> float:\n",
    "    return stats.laplace.pdf(x, loc=LAPLACE_LOC, scale=b)\n",
    "\n",
    "\n",
    "def pi_of_theta(theta: np.ndarray, p: np.ndarray, mu: float, sigma_sq: float) -> float:\n",
    "    return np.sum( np.exp(np.log(p) + stats.norm(mu, sigma_sq).logpdf(theta)))\n",
    "\n",
    "\n",
    "def e_of_pi_of_theta(theta: np.ndarray) -> float:\n",
    "    return np.mean((theta - 1)**2)\n",
    "\n",
    "n_trials = 5\n",
    "n_samples = 50_000\n",
    "\n",
    "\n",
    "# 3.1\n",
    "mu = [-1, 1]\n",
    "p = [0.5, 0.5]\n",
    "\n",
    "\n",
    "def importance_sample(n_trials: int, n_samples: int, b: float, p: np.ndarray, mu_1: np.ndarray, sigma_sq_1: np.ndarray) -> np.ndarray:\n",
    "    samples = np.zeros((n_trials, n_samples))\n",
    "    for i in range(n_trials):\n",
    "        for j in range(n_samples):\n",
    "            theta = sample_laplace_proposal(b)\n",
    "            importance_weight = pi_of_theta(theta, p, mu_1, sigma_sq_1) / pdf_laplace_proposal(theta, b)\n",
    "            samples[i,j] = e_of_pi_of_theta(theta) * importance_weight\n",
    "    return samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.24057457 2.2277798  2.24433238 2.2631532  2.24777513]\n",
      "0.01143172903287815\n",
      "2.2447230148148436\n"
     ]
    }
   ],
   "source": [
    "sigma_sq_1 = [.5, .5]\n",
    "b_1 = 2\n",
    "\n",
    "samples_3_1 = importance_sample(n_trials, n_samples, b_1, p, mu, sigma_sq_1)\n",
    "print(np.mean(samples_3_1, axis=1))\n",
    "print(np.mean(samples_3_1, axis=1).std())\n",
    "print(np.mean(samples_3_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.03804428 2.03787958 2.11819768 1.97057401 1.98966979]\n",
      "0.05110732401003963\n",
      "2.030873067336955\n"
     ]
    }
   ],
   "source": [
    "sigma_sq_2 = [.1, .1]\n",
    "b_2 = 1\n",
    "\n",
    "samples_3_2 = importance_sample(n_trials, n_samples, b_2, p, mu, sigma_sq_2)\n",
    "print(np.mean(samples_3_2, axis=1))\n",
    "print(np.mean(samples_3_2, axis=1).std())\n",
    "print(np.mean(samples_3_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(samples_3_1, samples_3_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rejection ABC for a dynamical model (6 pts)\n",
    "\n",
    "In this task we will develop an ABC sampler for the autoregressive (AR) model:\n",
    "$$ x_{t+1} = a x_t + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2). $$\n",
    "Throughout the exercise, we assume $x_0 = 1$. The model has two parameters, $a$ and $\\sigma$. We set priors\n",
    "$$ p(a) = \\mathrm{Uniform}(a;\\; 0, 1), \\quad p(\\sigma) = \\mathrm{Gamma}(\\sigma;\\; k_\\sigma, \\theta_\\sigma) $$\n",
    "with $k_\\sigma = 8, \\theta_\\sigma = 1/8$. Note that we use the shape/scale parametrisation also used by NumPy and that the prior is over $\\sigma$, not $\\sigma^2$ (also more consistent with NumPy parametrisation).\n",
    "\n",
    "1. Implement a function to simulate the AR process. Test your function by generating and plotting two independent realisations of length 200 with $a = 0.75$, $\\sigma = 0.2$. Notice how the sequences diverge relatively quickly and are essentially independent toward the end. *Hint*: Length 200 means that the generated sequence will take values $x_0, x_1, \\ldots, x_{199}$.\n",
    "2. Sample 5000 sequences from the AR process of length 200 with $a = 0.75$, $\\sigma = 0.2$. For each sequence, extract the last value. Compute the standard deviation of the last values across the 5000 simulated sequences and report it in Moodle.\n",
    "3. For the purpose of ABC sampling, we are going to summarize the sequences with the 2-dimensional summary statistics\n",
    "$$ S(X) = \\left( \\frac{1}{N} \\sum_{i=0}^{N-1} x_i^2, \\frac{1}{N-1} \\sum_{i=0}^{N-2} x_i x_{i+1} \\right). $$\n",
    "Load the the single observed sequence $X$ (the data) with the code below and evaluate $S(X)$ on the provided sequence. Report the two summary statistics of the data in Moodle.\n",
    "\n",
    "4. Implement an ABC sampler to infer the posterior over $a$ and $\\sigma$ given the single observed sequence $X$ loaded below using the simulator implemented above and the 2-dimensional summary statistics defined above. Run your sampler to generate samples with acceptance threshold $\\| S(X) - S(X^\\star)\\|_2 \\le \\epsilon$ with $\\epsilon = 0.2$.\n",
    "5. Report the approximate posterior means and standard deviations of $a$ and $\\sigma$ to Moodle.\n",
    "\n",
    "The required tolerance on the posterior means and standard deviations is $\\pm 0.03$.\n",
    "\n",
    "*Hints*:\n",
    "- Note that for the acceptance threshold we are using the standard Euclidean metric: $\\|v\\|_2 = \\sqrt{\\sum_{i} v_i^2}$.\n",
    "- The ABC sampler here can easily require tens of seconds or more when the number of samples is large, so you should be careful when increasing the number of samples. A reasonably good implementation should be able to reach the required accuracy in less than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv('https://raw.githubusercontent.com/lacerbi/compstats-files/main/data/ar_time_series_data.txt', header=None, sep='\\t')\n",
    "data = dataframe.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_prior(a: float) -> float:\n",
    "    return stats.uniform(0, 1)\n",
    "\n",
    "def sigma_log_prior(sigma: float) -> float:\n",
    "    return stats.gamma(8, 1/8).logpdf(sigma)\n",
    "\n",
    "def epsilon(sigma: float) -> float:\n",
    "    return stats.norm(0, sigma**2).rvs()\n",
    "\n",
    "def auto_regressive_model(x_t: float, alpha: float, epsilon_t: float) -> float:\n",
    "    return alpha * x_t + epsilon_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_abc(\n",
    "    coef: Callable[[],float],\n",
    "    sigma: Callable[[],float],\n",
    "    eps: Callable[[float], float],\n",
    "    x0: float = 1,\n",
    "    n_iterations: int = 200,\n",
    "):\n",
    "    x = np.zeros(n_iterations)\n",
    "    x[0] = x0\n",
    "    for i in range(1, n_iterations):\n",
    "        sigma_i = sigma()\n",
    "        x[i] = coef() * x[i-1] + eps(sigma_i)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1 = mcmc_abc(\n",
    "    coef = lambda: stats.uniform(0, 1).rvs(), \n",
    "    sigma = lambda: stats.gamma(8, 1/8).rvs(), \n",
    "    eps = lambda sigma: stats.norm(0, sigma**2).rvs(),\n",
    "    x0 = 1,\n",
    "    n_iterations = 200,\n",
    "    )\n",
    "\n",
    "chain_2 = mcmc_abc(\n",
    "    coef = lambda: stats.uniform(0, 1).rvs(), \n",
    "    sigma = lambda: stats.gamma(8, 1/8).rvs(), \n",
    "    eps = lambda sigma: stats.norm(0, sigma**2).rvs(),\n",
    "    x0 = 1,\n",
    "    n_iterations = 200,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_x_vectorised(x: np.ndarray) -> tuple[float, float]:\n",
    "    N = len(x)\n",
    "    x1 = np.sum(x[:-1] **2) / N\n",
    "    x2 = np.sum(x[:-2] * x[1:-1]) / (N - 1)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_x(x: np.ndarray) -> tuple[float, float]:\n",
    "    N = len(x)\n",
    "    x1 = 0\n",
    "    for i in range(N-1):\n",
    "        x1 += x[i]**2\n",
    "    x1 = x1 / N\n",
    "\n",
    "    x2 = 0\n",
    "    for i in range(N-2):\n",
    "        x2 += x[i] * x[i+1]\n",
    "    x2 = x2 / (N - 1)\n",
    "    return x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.305171069319515, 1.185813020421201)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_x(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computational-statistics-qlF0ErcH-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "53d6570113b994f255c5776c8cfb3ba753c6be772e819a2f7ee89343d6cab335"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
